import numpy as np 
import matplotlib.pyplot as plt 
X = np.array([[1, 2, 3], [1, 3, 4], [1, 4, 5], [1, 5, 6]]) 
y = np.array([7, 10, 13, 16])  
m, n = X.shape  
theta = np.zeros(n) 
def cost_function(X, y, theta): 
    m = len(y)  
    predictions = X.dot(theta) 
    cost = (1 / (2 * m)) * np.sum((predictions - y) ** 2) 
    return cost 
def gradient_descent(X, y, theta, learning_rate, iterations): 
    m = len(y) 
    cost_history = np.zeros(iterations) 
     
    for i in range(iterations): 
        predictions = X.dot(theta) 
         
        theta -= (learning_rate / m) * X.T.dot(predictions - y)  
         
        
        cost_history[i] = cost_function(X, y, theta) 
     
    return theta, cost_history 
learning_rate = 0.01 
iterations = 1500 
theta_optimal, cost_history = gradient_descent(X, y, theta, learning_rate, iterations) 
print("Optimized Theta:", theta_optimal) 
print("Final Cost:", cost_history[-1]) 
plt.figure(figsize=(8, 6)) 
plt.plot(range(iterations), cost_history, color='blue') 
plt.title('Cost Function History') 
plt.xlabel('Number of Iterations') 
plt.ylabel('Cost (J)') 
plt.grid(True) 
plt.show() 
predictions = X.dot(theta_optimal) 
plt.figure(figsize=(8, 6)) 
plt.scatter(range(len(y)), y, color='red', label='Actual values') 
plt.plot(range(len(y)), predictions, color='blue', label='Predicted values') 
plt.title('Actual vs Predicted values') 
plt.xlabel('Data Point Index') 
plt.ylabel('Target Value') 
plt.legend()  
plt.grid(True) 
plt.show() 
